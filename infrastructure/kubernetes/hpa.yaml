# Horizontal Pod Autoscaler for API Service
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: api-service-hpa
  namespace: mlops-housing
  labels:
    app: api-service
    app.kubernetes.io/name: api-service-hpa
    app.kubernetes.io/part-of: mlops-platform
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: api-service
  minReplicas: 2
  maxReplicas: 10
  metrics:
  # CPU-based scaling
  - type: Resource
    resource:
      name: cpu
      target:
        type: Utilization
        averageUtilization: 70
  # Memory-based scaling
  - type: Resource
    resource:
      name: memory
      target:
        type: Utilization
        averageUtilization: 80
  # Custom metrics (if you have custom metrics)
  # - type: Pods
  #   pods:
  #     metric:
  #       name: http_requests_per_second
  #     target:
  #       type: AverageValue
  #       averageValue: "1k"
  
  # Scaling behavior
  behavior:
    scaleDown:
      stabilizationWindowSeconds: 300  # 5 minutes
      policies:
      - type: Percent
        value: 50
        periodSeconds: 60
      - type: Pods
        value: 2
        periodSeconds: 60
      selectPolicy: Min
    scaleUp:
      stabilizationWindowSeconds: 60   # 1 minute
      policies:
      - type: Percent
        value: 100
        periodSeconds: 30
      - type: Pods
        value: 4
        periodSeconds: 30
      selectPolicy: Max
        
---
# Horizontal Pod Autoscaler for Predict Service
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: predict-service-hpa
  namespace: mlops-housing
  labels:
    app: predict-service
    app.kubernetes.io/name: predict-service-hpa
    app.kubernetes.io/part-of: mlops-platform
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: predict-service
  minReplicas: 2
  maxReplicas: 8
  metrics:
  # CPU-based scaling (ML workloads are CPU intensive)
  - type: Resource
    resource:
      name: cpu
      target:
        type: Utilization
        averageUtilization: 60  # Lower threshold for ML workloads
  # Memory-based scaling (ML models can be memory intensive)
  - type: Resource
    resource:
      name: memory
      target:
        type: Utilization
        averageUtilization: 75
        
  # Scaling behavior (more conservative for ML workloads)
  behavior:
    scaleDown:
      stabilizationWindowSeconds: 600  # 10 minutes (models take time to warm up)
      policies:
      - type: Percent
        value: 25    # Scale down more slowly
        periodSeconds: 120
      - type: Pods
        value: 1
        periodSeconds: 120
      selectPolicy: Min
    scaleUp:
      stabilizationWindowSeconds: 120  # 2 minutes
      policies:
      - type: Percent
        value: 50
        periodSeconds: 60
      - type: Pods
        value: 2
        periodSeconds: 60
      selectPolicy: Max
      
---
# Pod Disruption Budget for API Service
apiVersion: policy/v1
kind: PodDisruptionBudget
metadata:
  name: api-service-pdb
  namespace: mlops-housing
  labels:
    app: api-service
    app.kubernetes.io/name: api-service-pdb
    app.kubernetes.io/part-of: mlops-platform
spec:
  minAvailable: 50%
  selector:
    matchLabels:
      app: api-service
      
---
# Pod Disruption Budget for Predict Service
apiVersion: policy/v1
kind: PodDisruptionBudget
metadata:
  name: predict-service-pdb
  namespace: mlops-housing
  labels:
    app: predict-service
    app.kubernetes.io/name: predict-service-pdb
    app.kubernetes.io/part-of: mlops-platform
spec:
  minAvailable: 1  # At least 1 pod should be available
  selector:
    matchLabels:
      app: predict-service