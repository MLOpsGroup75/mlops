name: Data Pipeline

on:
  push:
    branches: [ main, develop ]
    paths:
      - 'data/**'
      - 'scripts/download_california_housing.py'
      - '.github/workflows/data-pipeline.yml'
  pull_request:
    branches: [ main ]
    paths:
      - 'data/**'
      - 'scripts/download_california_housing.py'
      - '.github/workflows/data-pipeline.yml'

env:
  PYTHON_VERSION: '3.9'

jobs:
  data-validation:
    runs-on: ubuntu-latest
    
    steps:
    - uses: actions/checkout@v4
    
    - name: Set up Python ${{ env.PYTHON_VERSION }}
      uses: actions/setup-python@v4
      with:
        python-version: ${{ env.PYTHON_VERSION }}
    
    - name: Cache pip dependencies
      uses: actions/cache@v3
      with:
        path: ~/.cache/pip
        key: ${{ runner.os }}-pip-data-${{ hashFiles('**/requirements.txt') }}
        restore-keys: |
          ${{ runner.os }}-pip-data-
          ${{ runner.os }}-pip-
    
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install pandas scikit-learn pytest flake8
        if [ -f requirements.txt ]; then pip install -r requirements.txt; fi
    
    - name: Lint data processing code
      run: |
        flake8 data/src/ --count --select=E9,F63,F7,F82 --show-source --statistics
        flake8 data/src/ --count --exit-zero --max-complexity=10 --max-line-length=127 --statistics
    
    - name: Data Pipeline Triggered
      run: |
        echo "üî• DATA PIPELINE TRIGGERED üî•"
        echo "================================="
        echo "Changes detected in data directory"
        echo "Running data validation and processing..."
        echo "================================="
        
        # Placeholder for actual data pipeline steps
        echo "üìä Step 1: Data quality checks"
        echo "üìä Step 2: Data schema validation"
        echo "üìä Step 3: Data preprocessing"
        echo "üìä Step 4: Feature engineering"
        echo "üìä Step 5: Data versioning with DVC"
        
        echo "================================="
        echo "‚úÖ Data pipeline completed successfully!"

  data-quality-checks:
    runs-on: ubuntu-latest
    needs: data-validation
    
    steps:
    - uses: actions/checkout@v4
    
    - name: Set up Python ${{ env.PYTHON_VERSION }}
      uses: actions/setup-python@v4
      with:
        python-version: ${{ env.PYTHON_VERSION }}
    
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install pandas scikit-learn numpy
        if [ -f requirements.txt ]; then pip install -r requirements.txt; fi
    
    - name: Run data quality checks (placeholder)
      run: |
        echo "üîç Running data quality checks..."
        echo "- Checking for missing values"
        echo "- Validating data types"
        echo "- Checking data ranges"
        echo "- Verifying data integrity"
        echo "‚úÖ All data quality checks passed!"

  data-preprocessing:
    runs-on: ubuntu-latest
    needs: data-quality-checks
    if: github.ref == 'refs/heads/main'
    
    steps:
    - uses: actions/checkout@v4
    
    - name: Set up Python ${{ env.PYTHON_VERSION }}
      uses: actions/setup-python@v4
      with:
        python-version: ${{ env.PYTHON_VERSION }}
    
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install pandas scikit-learn numpy
        if [ -f requirements.txt ]; then pip install -r requirements.txt; fi
    
    - name: Run data preprocessing (placeholder)
      run: |
        echo "‚öôÔ∏è Running data preprocessing pipeline..."
        echo "- Loading raw data"
        echo "- Cleaning data"
        echo "- Feature scaling"
        echo "- Train/test split"
        echo "- Saving processed data"
        echo "‚úÖ Data preprocessing completed!"
    
    - name: Upload processed data artifacts (placeholder)
      run: |
        echo "üì§ Uploading processed data artifacts..."
        echo "- Uploading to data storage"
        echo "- Updating data registry"
        echo "- Creating data version"
        echo "‚úÖ Data artifacts uploaded successfully!"

  notify-downstream:
    runs-on: ubuntu-latest
    needs: [data-validation, data-quality-checks, data-preprocessing]
    if: always() && github.ref == 'refs/heads/main'
    
    steps:
    - name: Notify model pipeline
      run: |
        echo "üì¢ Notifying downstream pipelines..."
        echo "Data pipeline completed. New data available for:"
        echo "- Model training pipeline"
        echo "- Model validation pipeline"
        echo "- Feature monitoring pipeline"
        echo "‚úÖ Notifications sent!"
