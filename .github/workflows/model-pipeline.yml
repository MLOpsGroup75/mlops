name: Model Pipeline

on:
  push:
    branches: [ main, develop ]
    paths:
      - 'model/**'
      - 'train_*.py'
      - '.github/workflows/model-pipeline.yml'
  pull_request:
    branches: [ main ]
    paths:
      - 'model/**'
      - 'train_*.py'
      - '.github/workflows/model-pipeline.yml'
  workflow_run:
    workflows: ["Data Pipeline"]
    types:
      - completed
    branches: [ main ]

env:
  PYTHON_VERSION: '3.9'
  MLFLOW_TRACKING_URI: 'http://localhost:5000'

jobs:
  model-validation:
    runs-on: ubuntu-latest

    steps:
    - uses: actions/checkout@v4

    - name: Check trigger context
      run: |
        if [ "${{ github.event.workflow_run.conclusion }}" = "success" ]; then
          echo "Model pipeline triggered by successful data pipeline completion!"
          echo "Data pipeline run: ${{ github.event.workflow_run.id }}"
          echo "Data pipeline commit: ${{ github.event.workflow_run.head_sha }}"
          echo "Data pipeline branch: ${{ github.event.workflow_run.head_branch }}"
        else
          echo "Model pipeline triggered by direct push/PR to model directory"
        fi

    - name: Set up Python ${{ env.PYTHON_VERSION }}
      uses: actions/setup-python@v4
      with:
        python-version: ${{ env.PYTHON_VERSION }}

    - name: Install DVC and pull latest data
      if: github.event.workflow_run.conclusion == 'success'
      run: |
        echo "Pulling latest data from DVC (triggered by data pipeline)..."
        python -m pip install --upgrade pip
        pip install dvc[s3]

        # Configure AWS credentials for DVC
        export AWS_ACCESS_KEY_ID=${{ secrets.GHA_MLOPS_AWS_ACCESS_KEY_ID }}
        export AWS_SECRET_ACCESS_KEY=${{ secrets.GHA_MLOPS_AWS_SECRET_ACCESS_KEY }}
        export AWS_DEFAULT_REGION=ap-south-1

        # Setup DVC remote
        dvc remote add -d s3remote s3://mlops-housing-dev-datasets || echo "Remote already exists"
        dvc remote modify s3remote region ap-south-1

        # Pull latest data
        dvc pull --all-branches
        echo "Latest data pulled from DVC!"

    - name: Cache pip dependencies
      uses: actions/cache@v3
      with:
        path: ~/.cache/pip
        key: ${{ runner.os }}-pip-model-${{ hashFiles('**/requirements.txt') }}
        restore-keys: |
          ${{ runner.os }}-pip-model-
          ${{ runner.os }}-pip-

    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install scikit-learn pandas numpy mlflow pytest flake8 joblib
        if [ -f requirements.txt ]; then pip install -r requirements.txt; fi

    - name: Lint model code
      run: |
        flake8 model/ --count --select=E9,F63,F7,F82 --show-source --statistics
        flake8 model/ --count --exit-zero --max-complexity=10 --max-line-length=127 --statistics

    - name: Model Pipeline Triggered
      run: |
        echo "MODEL PIPELINE TRIGGERED"
        echo "========================"
        echo "Changes detected in model directory"
        echo "Running model training and validation..."
        echo "===================================="

        # Placeholder for actual model pipeline steps

  model-training:
    runs-on: ubuntu-latest
    needs: model-validation

    steps:
    - uses: actions/checkout@v4

    - name: Set up Python ${{ env.PYTHON_VERSION }}
      uses: actions/setup-python@v4
      with:
        python-version: ${{ env.PYTHON_VERSION }}

    - name: Install DVC and pull latest data
      if: github.event.workflow_run.conclusion == 'success'
      run: |
        echo "Pulling latest data from DVC for model training..."
        python -m pip install --upgrade pip
        pip install dvc[s3]

        # Configure AWS credentials for DVC
        export AWS_ACCESS_KEY_ID=${{ secrets.GHA_MLOPS_AWS_ACCESS_KEY_ID }}
        export AWS_SECRET_ACCESS_KEY=${{ secrets.GHA_MLOPS_AWS_SECRET_ACCESS_KEY }}
        export AWS_DEFAULT_REGION=ap-south-1

        # Setup DVC remote
        dvc remote add -d s3remote s3://mlops-housing-dev-datasets || echo "Remote already exists"
        dvc remote modify s3remote region ap-south-1

        # Pull latest data
        dvc pull --all-branches
        echo "Latest data pulled from DVC for training!"

    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install scikit-learn pandas numpy mlflow joblib
        if [ -f requirements.txt ]; then pip install -r requirements.txt; fi

    - name: Run model training (placeholder)
      run: |
        echo "Starting model training pipeline..."

    - name: Model performance evaluation (placeholder)
      run: |
        echo "Evaluating model performance..."

  model-testing:
    runs-on: ubuntu-latest
    needs: model-validation

    steps:
    - uses: actions/checkout@v4

    - name: Set up Python ${{ env.PYTHON_VERSION }}
      uses: actions/setup-python@v4
      with:
        python-version: ${{ env.PYTHON_VERSION }}

    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install scikit-learn pandas numpy pytest pytest-cov
        if [ -f requirements.txt ]; then pip install -r requirements.txt; fi

    - name: Run model unit tests (placeholder)
      run: |
        echo "Running model unit tests..."

  model-registration:
    runs-on: ubuntu-latest
    needs: [model-training, model-testing]
    if: github.ref == 'refs/heads/main'

    steps:
    - uses: actions/checkout@v4

    - name: Set up Python ${{ env.PYTHON_VERSION }}
      uses: actions/setup-python@v4
      with:
        python-version: ${{ env.PYTHON_VERSION }}

    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install scikit-learn pandas numpy mlflow joblib
        if [ -f requirements.txt ]; then pip install -r requirements.txt; fi

    - name: Register model (placeholder)
      run: |
        echo "Registering trained model..."

    - name: Upload model artifacts (placeholder)
      run: |
        echo "Uploading model artifacts..."

  model-deployment-readiness:
    runs-on: ubuntu-latest
    needs: model-registration
    if: github.ref == 'refs/heads/main'

    steps:
    - name: Check deployment readiness (placeholder)
      run: |
        echo "Checking model deployment readiness..."

    - name: Notify deployment pipeline
      run: |
        echo "Notifying deployment pipeline..."
        echo "New model version available for deployment:"

  notify-downstream:
    runs-on: ubuntu-latest
    needs: [model-validation, model-training, model-testing, model-registration]
    if: always() && github.ref == 'refs/heads/main'

    steps:
    - name: Notify monitoring pipeline
      run: |
        echo "Notifying monitoring and downstream pipelines..."
        echo "Model pipeline completed."
